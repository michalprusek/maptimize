# GPU-enabled Backend Dockerfile for Maptimize
# Uses python:3.12-slim base with PyTorch CUDA 12.6 (for SAM 3 support)
# Requires nvidia runtime at container start: docker run --runtime=nvidia

# Stage 1: Build wheels
FROM python:3.12-slim AS wheel-builder

RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    cmake \
    gcc \
    g++ \
    git \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /wheels

COPY pyproject.toml ./

# Build PyTorch with CUDA 12.6 support (required for SAM 3)
RUN --mount=type=cache,target=/root/.cache/pip \
    pip wheel --no-cache-dir --wheel-dir /wheels \
    torch torchvision --extra-index-url https://download.pytorch.org/whl/cu126

# Build other ML dependencies
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install uv && \
    pip wheel --no-cache-dir --wheel-dir /wheels \
    ultralytics>=8.1.0 \
    "transformers>=4.56.0" \
    timm>=0.9.12 \
    pgvector>=0.3.0 \
    umap-learn>=0.5.7 \
    numba>=0.59.0 \
    scikit-learn>=1.4.0

# Stage 2: Runtime base
FROM python:3.12-slim AS runtime-base

RUN apt-get update && apt-get install -y --no-install-recommends \
    libgomp1 \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgl1 \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Stage 3: Production
FROM runtime-base AS production

WORKDIR /app

# Create non-root user
RUN useradd --create-home --shell /bin/bash app

# Copy pyproject.toml for dependency reference
COPY pyproject.toml ./

# Install uv and base dependencies
RUN pip install uv

# Install wheels from builder
COPY --from=wheel-builder /wheels /wheels
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install --no-cache-dir --no-index --find-links /wheels \
    torch torchvision && \
    pip install --no-cache-dir --find-links /wheels \
    ultralytics transformers timm pgvector umap-learn numba scikit-learn && \
    rm -rf /wheels

# Install SAM 3 dependencies first (required: numpy<2, einops, decord, pycocotools)
RUN pip install --no-cache-dir "numpy>=1.26,<2" einops decord pycocotools supervision

# Install SAM 3 from Facebook Research
RUN pip install --no-cache-dir git+https://github.com/facebookresearch/sam3.git

# Install remaining dependencies
RUN uv pip install --system -e "."

# Copy application code
COPY --chown=app:app . .

# Create directories
RUN mkdir -p data/uploads /app/weights /app/.cache/huggingface && \
    chown -R app:app /app

# Entrypoint script
COPY --chown=app:app <<'EOF' /app/docker-entrypoint.sh
#!/bin/bash
set -e

echo "=== Maptimize Backend Initialization ==="

# Check GPU availability (warn but don't fail - CPU fallback is acceptable)
echo "Checking compute devices..."
GPU_STATUS=$(python -c "
import torch
cuda = torch.cuda.is_available()
print(f'CUDA available: {cuda}')
if cuda:
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    mem = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print(f'Memory: {mem:.1f} GB')
    print(f'PyTorch version: {torch.__version__}')
    print(f'CUDA version: {torch.version.cuda}')
else:
    print('WARNING: Running in CPU mode - ML inference will be slow')
" 2>&1) || {
    echo "ERROR: GPU check failed with error:"
    echo "$GPU_STATUS"
    echo "WARNING: Continuing with potentially degraded performance"
}
echo "$GPU_STATUS"

# Check SAM 3 availability
SAM3_STATUS=$(python -c "
try:
    import sam3
    print('✓ SAM 3 installed')
except ImportError:
    print('⚠ SAM 3 not available')
" 2>&1) || true
echo "$SAM3_STATUS"

# Check YOLOv8 weights - these are REQUIRED for cell detection
YOLO_PATH="${YOLO_MODEL_PATH:-/app/weights/best.pt}"
if [ -f "$YOLO_PATH" ]; then
    SIZE=$(du -h "$YOLO_PATH" | cut -f1)
    echo "✓ YOLOv8 weights found: $YOLO_PATH ($SIZE)"
else
    echo ""
    echo "❌ ERROR: YOLOv8 custom weights not found at $YOLO_PATH"
    echo "   Cell detection will FAIL without trained weights."
    echo "   Mount weights directory: -v ./weights:/app/weights:ro"
    echo ""
    exit 1
fi

echo ""
echo "✅ Initialization complete"
echo "=== Starting Maptimize Backend ==="
echo ""

exec "$@"
EOF

RUN chmod +x /app/docker-entrypoint.sh

# Labels
LABEL maintainer="Maptimize"
LABEL service="maptimize-backend"

# Cleanup
RUN find /usr/local/lib/python3.12 -name "*.pyc" -delete 2>/dev/null || true && \
    find /usr/local/lib/python3.12 -name "__pycache__" -type d -delete 2>/dev/null || true && \
    rm -rf /root/.cache/pip

# Switch to non-root user
USER app

# Environment
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1
ENV PORT=8000
ENV OMP_NUM_THREADS=4
ENV MKL_NUM_THREADS=4
ENV HF_HOME=/app/.cache/huggingface
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512,expandable_segments:True

EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

ENTRYPOINT ["/app/docker-entrypoint.sh"]
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
